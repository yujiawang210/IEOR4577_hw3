{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Import Required Libraries ------\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "# ------ GloVe embedding dictionary ------\n",
    "glove_dim = 100  \n",
    "root_path = os.getcwd()\n",
    "glove_file = '/glove.twitter.27B/glove.twitter.27B.' + str(glove_dim) + 'd.txt'\n",
    "\n",
    "emb_index = {}\n",
    "glove = open(root_path+glove_file)\n",
    "for row, line in enumerate(glove):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    emb_index[word] = row\n",
    "glove.close()\n",
    "\n",
    "\n",
    "# ------ Define TwitterPreprocessor Class ------\n",
    "class TwitterPreprocessor:\n",
    "    \n",
    "    # - dunder function -\n",
    "    def __init__(self, text:str, max_length_tweet=30, max_length_dictionary=1000):\n",
    "        self.text = text\n",
    "        self.max_length_tweet = max_length_tweet\n",
    "        self.max_length_dictionary = max_length_dictionary\n",
    "    \n",
    "    # - supporting functions -\n",
    "    def remove_url(self):\n",
    "        pattern = re.compile(r'https?:\\/\\/[A-Za-z0-9\\/\\.\\-\\#]*')\n",
    "        self.text = re.sub(pattern=pattern, repl='', string=self.text)\n",
    "        return self\n",
    "        \n",
    "    def remove_hashtag(self):\n",
    "        pattern = re.compile(r'#\\w*')\n",
    "        self.text = re.sub(pattern=pattern, repl='', string=self.text)\n",
    "        return self\n",
    "    \n",
    "    def remove_mentions(self):\n",
    "        pattern = re.compile(r'@\\w*')\n",
    "        self.text = re.sub(pattern=pattern, repl='', string=self.text)\n",
    "        return self\n",
    "    \n",
    "    def remove_twitter_handle(self):\n",
    "        pattern = re.compile(r'RT')\n",
    "        self.text = re.sub(pattern=pattern, repl='', string=self.text)\n",
    "        return self\n",
    "    \n",
    "    def remove_numbers(self):\n",
    "        pattern = re.compile(r'[0-9]+')\n",
    "        self.text = re.sub(pattern=pattern, repl='', string=self.text)\n",
    "        return self\n",
    "        \n",
    "    def remove_punctuation(self):\n",
    "        pattern = re.compile(r'[^\\w\\s]')\n",
    "        self.text = re.sub(pattern=pattern, repl='', string=self.text)\n",
    "        return self\n",
    "        \n",
    "    def lower(self):\n",
    "        self.text = self.text.lower()\n",
    "        return self\n",
    "    \n",
    "    # - twitter preprocessor main methods -\n",
    "    def clean_text(self):\n",
    "        return self\\\n",
    "            .remove_url()\\\n",
    "            .remove_hashtag()\\\n",
    "            .remove_mentions()\\\n",
    "            .remove_twitter_handle()\\\n",
    "            .remove_numbers()\\\n",
    "            .remove_punctuation()\\\n",
    "            .lower()\n",
    "\n",
    "    def tokenize_text(self):\n",
    "        tknzr = TweetTokenizer()\n",
    "        self.text = tknzr.tokenize(self.text)\n",
    "        return self\n",
    "    \n",
    "    def replace_token_with_index(self):\n",
    "        for i in range(len(self.text)):\n",
    "            self.text[i] = emb_index[self.text[i]]\n",
    "        return self\n",
    "    \n",
    "    def pad_sequence(self):\n",
    "        max_length_tweet = self.max_length_tweet\n",
    "        if len(self.text) < max_length_tweet:\n",
    "            self.text.extend([0] * (max_length_tweet - len(self.text)))\n",
    "        elif len(self.text) >= max_length_tweet:\n",
    "            self.text = self.text[0:max_length_tweet]\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = 'RT @ruslantrad: For the last few days, Russia has increased its pressure on Idlib. This campaign escalates the last hours. There is mass'\n",
    "tweet = TwitterPreprocessor(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  for the last few days russia has increased its pressure on idlib this campaign escalates the last hours there is mass'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.clean_text()\n",
    "tweet.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'the',\n",
       " 'last',\n",
       " 'few',\n",
       " 'days',\n",
       " 'russia',\n",
       " 'has',\n",
       " 'increased',\n",
       " 'its',\n",
       " 'pressure',\n",
       " 'on',\n",
       " 'idlib',\n",
       " 'this',\n",
       " 'campaign',\n",
       " 'escalates',\n",
       " 'the',\n",
       " 'last',\n",
       " 'hours',\n",
       " 'there',\n",
       " 'is',\n",
       " 'mass']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.tokenize_text()\n",
    "tweet.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37,\n",
       " 13,\n",
       " 288,\n",
       " 1086,\n",
       " 455,\n",
       " 6338,\n",
       " 215,\n",
       " 20520,\n",
       " 221,\n",
       " 5849,\n",
       " 46,\n",
       " 203603,\n",
       " 53,\n",
       " 6078,\n",
       " 219797,\n",
       " 13,\n",
       " 288,\n",
       " 869,\n",
       " 175,\n",
       " 32,\n",
       " 6865]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.replace_token_with_index()\n",
    "tweet.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37,\n",
       " 13,\n",
       " 288,\n",
       " 1086,\n",
       " 455,\n",
       " 6338,\n",
       " 215,\n",
       " 20520,\n",
       " 221,\n",
       " 5849,\n",
       " 46,\n",
       " 203603,\n",
       " 53,\n",
       " 6078,\n",
       " 219797,\n",
       " 13,\n",
       " 288,\n",
       " 869,\n",
       " 175,\n",
       " 32,\n",
       " 6865,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.pad_sequence()\n",
    "tweet.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
